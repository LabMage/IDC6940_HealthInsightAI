---
title: "Writing a great story for data science projects - spring 2025"
subtitle: "This is a Report Template Quarto"
<<<<<<< HEAD
author: "Boiko Elena, Razo Jaquelin (Advisor: Dr. Cohen)"
=======
author: "Students names (Advisor: Dr. Cohen)"
>>>>>>> e2b4ef23a3b6d1e01ddf90e78672a80d4d5d4bd4
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!
:::

## Introduction

The introduction should:

-   Develop a storyline that captures attention and maintains interest.

-   Your audience is your peers

-   Clearly state the problem or question you're addressing.

<!-- -->

-   Introduce why it is relevant needs.

-   Provide an overview of your approach.

Example of writing including citing references:

*This is an introduction to .....  The KNN set of rules is a simple but powerful machine learning set of rules used for
categorization and regression. It's far a non-parametric approach that makes predictions based
totally on the nearest k-neighbours in a dataset. KNN is widely used in healthcare and scientific
studies to expect and classify sicknesses primarily based on the affected personâ€™s data. The
intention of this work is to predict the threat of growing type 2 diabetes using the KNN set of
rules

<<<<<<< HEAD
The PCA [@daffertshofer2004pca]*. Topology can be used in machine
learning [@adams2021topology]

KNN may be used for diabetes prediction [@panwar2016k]. 

The [@uddin2022comparative] provides an insightful comparison of K-Nearest Neighbors (KNN) and its variants for disease prediction, showcasing the benefits of distance-weighted KNN in improving accuracy and robustness against noisy data. 

The study [@suriya2023type] showed that KNN performs better on smaller datasets, achieving higher accuracy and fewer false predictions when the data is reduced in size or preprocessed.

The [@iparraguirre2023application]provides valuable insights into the application of ML models for diabetes prediction, demonstrating the effectiveness of K-NN and BNB in handling imbalanced datasets. The inclusion of SMOTE and PCA highlights the importance of preprocessing in improving model performance. 

The use of the KNN imputer [@altamimi2024automated] significantly improves model performance, demonstrating its potential for medical datasets

This comprehensive review [@syriopoulos2023k] discusses the strengths, weaknesses, applications, and recent developments of the k-Nearest Neighbors algorithm, offering a valuable resource for understanding its role in various data science tasks, including disease diagnosis.

The study [@theerthagiri2022diagnosis] highlights the superior performance of the MLP algorithm, emphasizing deep learning techniques over traditional machine learning methods. While also using the Pima Indians Diabetes dataset, this study applies preprocessing techniques, feature selection, and model evaluation steps in more detail.



=======
The PCA [@daffertshofer2004pca]*. Topology can be used in machine learning [@adams2021topology]
>>>>>>> e2b4ef23a3b6d1e01ddf90e78672a80d4d5d4bd4

*This is my work and I want to add more work...*

## Methods

-   Detail the models or algorithms used.

-   Justify your choices based on the problem and data.

*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum
of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is
unknown and* $\varepsilon_i$ *some errors. With the help of this
definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*


*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}

```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References
